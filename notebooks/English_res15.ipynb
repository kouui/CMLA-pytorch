{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import pickle\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from seqItem import SeqItem\n",
    "from util import set_status, save_score_to_text\n",
    "from model import CMLANet\n",
    "from dataset import CMLADataset\n",
    "from score import score_aspect, score_opinion\n",
    "\n",
    "from train import create_context_window, LossFunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "# Configuration Parameters\n",
    "#-----------------------------------------------------------------------------\n",
    "args = {\n",
    "    \"data\" : \"../data/res15/final_input_res15\",\n",
    "    \"embModel\" : \"../data/res15/word_embeddings200_res15\",\n",
    "    \"logStatus\" : \"terminal\"\n",
    "}\n",
    "#-----------------------------------------------------------------------------\n",
    "# Learning Control Hyperparameters\n",
    "#-----------------------------------------------------------------------------\n",
    "params = {\n",
    "    \"version\" : \"English\",\n",
    "    \"text\"    : \"../txt/outcome.txt\",\n",
    "    \"lr\" : 0.05,\n",
    "    \"win\" : 3,\n",
    "    \"nHidden\" : 50,\n",
    "    \"nEmbedDimension\" : 200,\n",
    "    \"nClass\" : 3,\n",
    "    \"batchSize\" : 1,\n",
    "    \"nEpoch\" : 20,\n",
    "    \"evaluateStep\" : 500,\n",
    "    \"dropout\" : 0.3,\n",
    "    \"device\"  : torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    \"save\" : True,\n",
    "}\n",
    "#-----------------------------------------------------------------------------\n",
    "# Data and Embed Model Loading\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "s_ = \"loading data\"\n",
    "set_status(s_=s_, status_=args[\"logStatus\"])\n",
    "\n",
    "with open(args[\"data\"], 'rb') as handle:\n",
    "    vocab, train_seq_list, test_seq_list = pickle.load(handle)\n",
    "\n",
    "\n",
    "s_ = \"loading embed model\"\n",
    "set_status(s_=s_, status_=args[\"logStatus\"])\n",
    "\n",
    "with open(args[\"embModel\"], 'rb') as handle:\n",
    "    emb_model = pickle.load(handle, encoding=\"bytes\")\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# model initialization\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "s_ = \"initializing network model\"\n",
    "set_status(s_=s_, status_=args[\"logStatus\"])\n",
    "\n",
    "net = CMLANet(nh=params[\"nHidden\"], nc=params[\"nClass\"],\n",
    "              de=params[\"nEmbedDimension\"], cs=params[\"win\"], bs=params[\"batchSize\"])\n",
    "net.double().to(params[\"device\"])\n",
    "\n",
    "#-- set dropout in net to params[\"dropout\"] here\n",
    "net.set_dropout_rate(params[\"dropout\"])\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# optimizer\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "#optimizer = torch.optim.SGD(params=net.parameters(), lr=params[\"lr\"], momentum=0.9, weight_decay=0.0)\n",
    "optimizer = torch.optim.Adam(params=net.parameters(), lr=params[\"lr\"]*0.1, weight_decay=0, amsgrad=False)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# dataset and dataloader\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "s_ = \"building dataset and dataloader\"\n",
    "set_status(s_=s_, status_=args[\"logStatus\"])\n",
    "\n",
    "dataset = {\n",
    "    \"train\" : CMLADataset(data_list=train_seq_list, emb_model=emb_model),\n",
    "    \"test\"  : CMLADataset(data_list=test_seq_list, emb_model=emb_model)\n",
    "}\n",
    "dataset[\"train\"].set_n_emb_dim(params[\"nEmbedDimension\"])\n",
    "dataset[\"test\"].set_n_emb_dim(params[\"nEmbedDimension\"])\n",
    "\n",
    "s_ = f\"length of train set : {len(dataset['train'])}\"\n",
    "set_status(s_=s_, status_=args[\"logStatus\"])\n",
    "s_ = f\"length of test set : {len(dataset['test'])}\"\n",
    "set_status(s_=s_, status_=args[\"logStatus\"])\n",
    "\n",
    "#-- batch_size must be 1 because of the variable length of node\n",
    "dataloader = {}\n",
    "for key, value in dataset.items():\n",
    "    dataloader[key] = torch.utils.data.DataLoader(value,\n",
    "                                                  batch_size=params[\"batchSize\"],\n",
    "                                                  shuffle=True,\n",
    "                                                  num_workers=0)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# training epochs\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "s_ = \"start training\"\n",
    "set_status(s_=s_, status_=args[\"logStatus\"])\n",
    "\n",
    "min_error = float(\"inf\")\n",
    "for epoch in range(1, params[\"nEpoch\"]+1):\n",
    "\n",
    "    net.train()\n",
    "    epoch_error = 0.\n",
    "    count = 0\n",
    "    for i_batch, batch in enumerate(dataloader[\"train\"]):\n",
    "\n",
    "        h_input, ya_label, yo_label, index2word, index_embed, sent = batch\n",
    "        h_input = h_input.to(params[\"device\"])\n",
    "        ya_label = ya_label.to(params[\"device\"])\n",
    "        yo_label = yo_label.to(params[\"device\"])\n",
    "\n",
    "        sent = list( zip(*sent) )\n",
    "        seq_size = h_input.shape[1]\n",
    "\n",
    "        now = time.time()\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# training sequence(s)\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "        context_words = torch.tensor(\n",
    "                     create_context_window(index2word, params[\"win\"], seq_size),\n",
    "                     dtype=torch.uint8 ).to(params[\"device\"])\n",
    "\n",
    "\n",
    "        #-- ya_pred, yo_pred : (bs, n_word, ny)\n",
    "        ya_pred, yo_pred = net(context_words[:,:,:], h_input[:,:,:])\n",
    "\n",
    "        error = LossFunc(ya_pred, yo_pred, ya_label.detach(), yo_label.detach())\n",
    "        net.zero_grad()\n",
    "        error.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# modify embedding model\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "        h_input_new = net.h_input.detach().numpy()\n",
    "        for k in range(h_input_new.shape[0]):\n",
    "            for i in index2word[k,:].tolist():\n",
    "                try:\n",
    "                    j = index_embed[k,i].data.item()\n",
    "                    emb_model[:, j] = h_input_new[k,i,:]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        epoch_error += error\n",
    "        count += 1\n",
    "\n",
    "        s_ = f\"epoch: {epoch:02d} i_batch: {i_batch:05d} error: {error:.2f} \"\n",
    "        s_ += f\"time collapsed: {time.time()-now:.2f}[sec]\"\n",
    "        set_status(s_=s_, status_=args[\"logStatus\"])\n",
    "\n",
    "        #if i_batch > 100:\n",
    "        #    break\n",
    "    epoch_error /= count\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# evaluate here\n",
    "#-----------------------------------------------------------------------------\n",
    "    if True:\n",
    "        s_ = \"Evaluating....\"\n",
    "        set_status(s_=s_, status_=args[\"logStatus\"])\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "\n",
    "            true_a = []\n",
    "            true_o = []\n",
    "            pred_a = []\n",
    "            pred_o = []\n",
    "\n",
    "            for i_batch, batch in enumerate(dataloader[\"test\"]):\n",
    "\n",
    "                h_input, ya_label, yo_label, index2word, index_embed, sent = batch\n",
    "                h_input = h_input.to(params[\"device\"])\n",
    "                ya_label = ya_label.to(params[\"device\"])\n",
    "                yo_label = yo_label.to(params[\"device\"])\n",
    "\n",
    "                sent = list( zip(*sent) )\n",
    "                seq_size = h_input.shape[1]\n",
    "\n",
    "                context_words = torch.tensor(\n",
    "                             create_context_window(index2word, params[\"win\"], seq_size),\n",
    "                             dtype=torch.uint8 ).to(params[\"device\"])\n",
    "\n",
    "                ya_pred, yo_pred = net(context_words[:,:,:], h_input[:,:,:])\n",
    "\n",
    "                ya_predLabel = ya_pred.argmax(axis=2)\n",
    "                yo_predLabel = yo_pred.argmax(axis=2)\n",
    "\n",
    "                ##true_list.append([str(y) for y in y_label[0,:]])\n",
    "                true_a.append([str(y) for y in ya_label[0,:]])\n",
    "                true_o.append([str(y) for y in yo_label[0,:]])\n",
    "                pred_a.append([str(y) for y in ya_predLabel[0,:]])\n",
    "                pred_o.append([str(y) for y in yo_predLabel[0,:]])\n",
    "\n",
    "            precision_as, recall_as, f1_as = score_aspect(true_a, pred_a)\n",
    "            precision_op, recall_op, f1_op = score_opinion(true_o, pred_o)\n",
    "\n",
    "            save_score_to_text(params[\"text\"], epoch, precision_as, recall_as, f1_as, precision_op, recall_op, f1_op)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# saving model here\n",
    "#-----------------------------------------------------------------------------\n",
    "    #-- save parameters if the current model is better than previous best model\n",
    "    if params[\"save\"] and  epoch_error < min_error:\n",
    "        min_error = epoch_error\n",
    "\n",
    "        s_ = \"saving model\"\n",
    "        set_status(s_=s_, status_=args[\"logStatus\"])\n",
    "        checkpoint = {\n",
    "                \"model state\" : net.state_dict(),\n",
    "            }\n",
    "        folder = f\"../checkpoints/{params['version']}\"\n",
    "        if not os.path.exists(folder) : os.mkdir(folder)\n",
    "        torch.save(checkpoint, os.path.join(folder, f\"checkpoint_epoch_{epoch}.pkl\") )\n",
    "#-----------------------------------------------------------------------------\n",
    "    #-- done with epoch\n",
    "    s_ = f\"done with epoch {epoch:02d}, epoch_error = {epoch_error:.2f}, min_error = {min_error:.2f}\"\n",
    "    set_status(s_=s_, status_=args[\"logStatus\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
